{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Name_Entity_POS_Tagging.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPKRO7wZDZezpSNb/CO4QdI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ameyas1/Entity_Recognition_POS_Tagging/blob/master/Name_Entity_POS_Tagging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCr5anqMN2mB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3938eef5-a9ee-4160-f0be-45fdb1dcdf36"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "plt.style.use(\"ggplot\")\n",
        "\n",
        "import tensorflow as tf\n",
        "print('Tensorflow version:', tf.__version__)\n",
        "print('GPU detected:', tf.config.list_physical_devices('GPU'))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version: 2.2.0\n",
            "GPU detected: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsaZ-tyxOZVn",
        "colab_type": "text"
      },
      "source": [
        "*Essential info about tagged entities*:\n",
        "- geo = Geographical Entity\n",
        "- org = Organization\n",
        "- per = Person\n",
        "- gpe = Geopolitical Entity\n",
        "- tim = Time indicator\n",
        "- art = Artifact\n",
        "- eve = Event\n",
        "- nat = Natural Phenomenon"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-sC0dFwLgrV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "91b9f85d-4756-46a0-dc22-30c016ebb82d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_9OkWgDOQK0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 982
        },
        "outputId": "2d3f49fe-b065-406e-8579-bdd4dcdd25de"
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/My Drive/ner_dataset.csv\", encoding=\"latin1\")\n",
        "data = data.fillna(method=\"ffill\")\n",
        "data.head(30)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>through</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>London</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-geo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>to</td>\n",
              "      <td>TO</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>protest</td>\n",
              "      <td>VB</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>war</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>in</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Iraq</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-geo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>and</td>\n",
              "      <td>CC</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>demand</td>\n",
              "      <td>VB</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>withdrawal</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>British</td>\n",
              "      <td>JJ</td>\n",
              "      <td>B-gpe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>troops</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>from</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>that</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>country</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Sentence: 2</td>\n",
              "      <td>Families</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Sentence: 2</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Sentence: 2</td>\n",
              "      <td>soldiers</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Sentence: 2</td>\n",
              "      <td>killed</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Sentence: 2</td>\n",
              "      <td>in</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Sentence: 2</td>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Sentence #           Word  POS    Tag\n",
              "0   Sentence: 1      Thousands  NNS      O\n",
              "1   Sentence: 1             of   IN      O\n",
              "2   Sentence: 1  demonstrators  NNS      O\n",
              "3   Sentence: 1           have  VBP      O\n",
              "4   Sentence: 1        marched  VBN      O\n",
              "5   Sentence: 1        through   IN      O\n",
              "6   Sentence: 1         London  NNP  B-geo\n",
              "7   Sentence: 1             to   TO      O\n",
              "8   Sentence: 1        protest   VB      O\n",
              "9   Sentence: 1            the   DT      O\n",
              "10  Sentence: 1            war   NN      O\n",
              "11  Sentence: 1             in   IN      O\n",
              "12  Sentence: 1           Iraq  NNP  B-geo\n",
              "13  Sentence: 1            and   CC      O\n",
              "14  Sentence: 1         demand   VB      O\n",
              "15  Sentence: 1            the   DT      O\n",
              "16  Sentence: 1     withdrawal   NN      O\n",
              "17  Sentence: 1             of   IN      O\n",
              "18  Sentence: 1        British   JJ  B-gpe\n",
              "19  Sentence: 1         troops  NNS      O\n",
              "20  Sentence: 1           from   IN      O\n",
              "21  Sentence: 1           that   DT      O\n",
              "22  Sentence: 1        country   NN      O\n",
              "23  Sentence: 1              .    .      O\n",
              "24  Sentence: 2       Families  NNS      O\n",
              "25  Sentence: 2             of   IN      O\n",
              "26  Sentence: 2       soldiers  NNS      O\n",
              "27  Sentence: 2         killed  VBN      O\n",
              "28  Sentence: 2             in   IN      O\n",
              "29  Sentence: 2            the   DT      O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpI5vE5AOy6f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c336acb9-e6f1-47c6-c532-a6f8aa1f3cfd"
      },
      "source": [
        "print(\"Unique words in corpus:\", data['Word'].nunique())\n",
        "print(\"Unique tags in corpus:\", data['Tag'].nunique())\n",
        "print(\"Unique POS in corpus:\", data['POS'].nunique())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique words in corpus: 35178\n",
            "Unique tags in corpus: 17\n",
            "Unique POS in corpus: 42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5TPPEWpPzgC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c7902631-a08f-4143-fe1a-1b844eb645c9"
      },
      "source": [
        "data['Tag'].unique()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['O', 'B-geo', 'B-gpe', 'B-per', 'I-geo', 'B-org', 'I-org', 'B-tim',\n",
              "       'B-art', 'I-art', 'I-per', 'I-gpe', 'I-tim', 'B-nat', 'B-eve',\n",
              "       'I-eve', 'I-nat'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFj2Xm36P5AF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "1d38be9e-2e02-4e58-d21b-fc816754fd47"
      },
      "source": [
        "data['POS'].unique()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['NNS', 'IN', 'VBP', 'VBN', 'NNP', 'TO', 'VB', 'DT', 'NN', 'CC',\n",
              "       'JJ', '.', 'VBD', 'WP', '``', 'CD', 'PRP', 'VBZ', 'POS', 'VBG',\n",
              "       'RB', ',', 'WRB', 'PRP$', 'MD', 'WDT', 'JJR', ':', 'JJS', 'WP$',\n",
              "       'RP', 'PDT', 'NNPS', 'EX', 'RBS', 'LRB', 'RRB', '$', 'RBR', ';',\n",
              "       'UH', 'FW'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD6dvzJKOqAn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = list(set(data[\"Word\"].values))\n",
        "words.append(\"PAD\")\n",
        "num_words = len(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVLPXc4MQJgo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0bd3a1c9-2d2f-40a2-fe60-6bcf62c798fc"
      },
      "source": [
        "num_words"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35179"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdw_H7gSPhhK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9a6ca7d6-d3f4-4f96-e0ea-11691f1f4aa3"
      },
      "source": [
        "tags = list(set(data[\"Tag\"].values))\n",
        "num_tags = len(tags)\n",
        "num_tags"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cKJ3PchPhk9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "16cba611-9ab3-4b9e-cfaa-69e869849052"
      },
      "source": [
        "POS = list(set(data[\"POS\"].values))\n",
        "POS.append('PPAD')\n",
        "num_POS = len(POS)\n",
        "num_POS"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pJcvde3Tc-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
        "                                                           s[\"POS\"].values.tolist(),\n",
        "                                                           s[\"Tag\"].values.tolist())]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dlWRcRVTiDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grouped = data.groupby(\"Sentence #\").apply(agg_func)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDWf7vpCTkAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = [s for s in grouped]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJ54Bdw0TppA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "outputId": "c4c1e13f-cc9c-4bb0-a4c2-1530d1c35cc7"
      },
      "source": [
        "sentences[:2]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('Thousands', 'NNS', 'O'),\n",
              "  ('of', 'IN', 'O'),\n",
              "  ('demonstrators', 'NNS', 'O'),\n",
              "  ('have', 'VBP', 'O'),\n",
              "  ('marched', 'VBN', 'O'),\n",
              "  ('through', 'IN', 'O'),\n",
              "  ('London', 'NNP', 'B-geo'),\n",
              "  ('to', 'TO', 'O'),\n",
              "  ('protest', 'VB', 'O'),\n",
              "  ('the', 'DT', 'O'),\n",
              "  ('war', 'NN', 'O'),\n",
              "  ('in', 'IN', 'O'),\n",
              "  ('Iraq', 'NNP', 'B-geo'),\n",
              "  ('and', 'CC', 'O'),\n",
              "  ('demand', 'VB', 'O'),\n",
              "  ('the', 'DT', 'O'),\n",
              "  ('withdrawal', 'NN', 'O'),\n",
              "  ('of', 'IN', 'O'),\n",
              "  ('British', 'JJ', 'B-gpe'),\n",
              "  ('troops', 'NNS', 'O'),\n",
              "  ('from', 'IN', 'O'),\n",
              "  ('that', 'DT', 'O'),\n",
              "  ('country', 'NN', 'O'),\n",
              "  ('.', '.', 'O')],\n",
              " [('Iranian', 'JJ', 'B-gpe'),\n",
              "  ('officials', 'NNS', 'O'),\n",
              "  ('say', 'VBP', 'O'),\n",
              "  ('they', 'PRP', 'O'),\n",
              "  ('expect', 'VBP', 'O'),\n",
              "  ('to', 'TO', 'O'),\n",
              "  ('get', 'VB', 'O'),\n",
              "  ('access', 'NN', 'O'),\n",
              "  ('to', 'TO', 'O'),\n",
              "  ('sealed', 'JJ', 'O'),\n",
              "  ('sensitive', 'JJ', 'O'),\n",
              "  ('parts', 'NNS', 'O'),\n",
              "  ('of', 'IN', 'O'),\n",
              "  ('the', 'DT', 'O'),\n",
              "  ('plant', 'NN', 'O'),\n",
              "  ('Wednesday', 'NNP', 'B-tim'),\n",
              "  (',', ',', 'O'),\n",
              "  ('after', 'IN', 'O'),\n",
              "  ('an', 'DT', 'O'),\n",
              "  ('IAEA', 'NNP', 'B-org'),\n",
              "  ('surveillance', 'NN', 'O'),\n",
              "  ('system', 'NN', 'O'),\n",
              "  ('begins', 'VBZ', 'O'),\n",
              "  ('functioning', 'VBG', 'O'),\n",
              "  ('.', '.', 'O')]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCWJvyrlT_kC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word2idx = {w: i for i, w in enumerate(words)}\n",
        "tag2idx = {t: i for i, t in enumerate(tags)}\n",
        "POS2idx = {p: i for i, p in enumerate(POS)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuzusUvMMEpf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 760
        },
        "outputId": "1ae6e5d0-08ad-4a6e-847c-78cceb3c2b5b"
      },
      "source": [
        "POS2idx"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'$': 16,\n",
              " ',': 2,\n",
              " '.': 6,\n",
              " ':': 21,\n",
              " ';': 1,\n",
              " 'CC': 27,\n",
              " 'CD': 38,\n",
              " 'DT': 37,\n",
              " 'EX': 24,\n",
              " 'FW': 30,\n",
              " 'IN': 33,\n",
              " 'JJ': 28,\n",
              " 'JJR': 25,\n",
              " 'JJS': 22,\n",
              " 'LRB': 20,\n",
              " 'MD': 26,\n",
              " 'NN': 40,\n",
              " 'NNP': 5,\n",
              " 'NNPS': 29,\n",
              " 'NNS': 32,\n",
              " 'PDT': 10,\n",
              " 'POS': 34,\n",
              " 'PPAD': 42,\n",
              " 'PRP': 12,\n",
              " 'PRP$': 3,\n",
              " 'RB': 7,\n",
              " 'RBR': 13,\n",
              " 'RBS': 14,\n",
              " 'RP': 23,\n",
              " 'RRB': 9,\n",
              " 'TO': 41,\n",
              " 'UH': 19,\n",
              " 'VB': 15,\n",
              " 'VBD': 31,\n",
              " 'VBG': 11,\n",
              " 'VBN': 18,\n",
              " 'VBP': 0,\n",
              " 'VBZ': 4,\n",
              " 'WDT': 35,\n",
              " 'WP': 17,\n",
              " 'WP$': 39,\n",
              " 'WRB': 8,\n",
              " '``': 36}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlUIN5lTUctV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "18c3a408-995d-4e42-c22b-cdee63122615"
      },
      "source": [
        "plt.hist([len(s) for s in sentences], bins=100)\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hofT_YS7UgSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_len = 70\n",
        "\n",
        "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
        "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=word2idx[\"PAD\"])\n",
        "\n",
        "y1 = [[tag2idx[w[2]] for w in s] for s in sentences]\n",
        "y1 = pad_sequences(maxlen=max_len, sequences=y1, padding=\"post\", value=tag2idx[\"O\"])\n",
        "\n",
        "y2 = [[POS2idx[w[1]] for w in s] for s in sentences]\n",
        "y2 = pad_sequences(maxlen=max_len, sequences=y2, padding=\"post\", value=POS2idx[\"PPAD\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_KL16TdXEu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y1_train, y1_test, y2_train, y2_test = train_test_split(X, y1, y2, test_size=0.2, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rT7ukTcXJkP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, Masking\n",
        "from tensorflow.keras.layers import TimeDistributed, SpatialDropout1D, Bidirectional"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZzoIXHjXmNN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "outputId": "cb6c4a35-0772-43d8-eb2c-0aa34455dc8e"
      },
      "source": [
        "input_word = Input(shape=(max_len,))\n",
        "model = Embedding(input_dim=num_words, output_dim=50, input_length=max_len)(input_word)\n",
        "model = Masking(mask_value=word2idx[\"PAD\"])(model)\n",
        "model = SpatialDropout1D(0.1)(model)\n",
        "model = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1))(model)\n",
        "model = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1))(model)\n",
        "tag = TimeDistributed(Dense(num_tags, activation=\"softmax\"),name='tag')(model)\n",
        "pos = TimeDistributed(Dense(num_POS, activation=\"softmax\"),name='POS')(model)\n",
        "model = Model(input_word, [tag,pos])\n",
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 70)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 70, 50)       1758950     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "masking (Masking)               (None, 70, 50)       0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d (SpatialDropo (None, 70, 50)       0           masking[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 70, 200)      120800      spatial_dropout1d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 70, 200)      240800      bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tag (TimeDistributed)           (None, 70, 17)       3417        bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "POS (TimeDistributed)           (None, 70, 43)       8643        bidirectional_1[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 2,132,610\n",
            "Trainable params: 2,132,610\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hXO-lEdYNUD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=\"accuracy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZN4erFO7ZXo3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "# from livelossplot.tf_keras import PlotLossesCallback"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9Wrc_LIZdhM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "outputId": "a7180f00-8e06-450a-99cf-a1649761ac13"
      },
      "source": [
        "%%time\n",
        "\n",
        "chkpt = ModelCheckpoint(\"sentence_tags_pos.h5\", monitor='val_loss',verbose=1, save_best_only=True, save_weights_only=True, mode='min')\n",
        "\n",
        "# early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=1, verbose=0, mode='max', baseline=None, restore_best_weights=False)\n",
        "\n",
        "callbacks = [chkpt]\n",
        "\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=[y1_train,y2_train],\n",
        "    validation_data=(x_test,[y1_test,y2_test]),\n",
        "    batch_size=32, \n",
        "    epochs=10,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1199/1199 [==============================] - ETA: 0s - loss: 0.6028 - tag_loss: 0.1533 - POS_loss: 0.4494 - tag_accuracy: 0.9656 - POS_accuracy: 0.8783\n",
            "Epoch 00001: val_loss improved from inf to 0.14176, saving model to sentence_tags_pos.h5\n",
            "1199/1199 [==============================] - 1115s 930ms/step - loss: 0.6028 - tag_loss: 0.1533 - POS_loss: 0.4494 - tag_accuracy: 0.9656 - POS_accuracy: 0.8783 - val_loss: 0.1418 - val_tag_loss: 0.0633 - val_POS_loss: 0.0785 - val_tag_accuracy: 0.9834 - val_POS_accuracy: 0.9808\n",
            "Epoch 2/10\n",
            "1199/1199 [==============================] - ETA: 0s - loss: 0.0934 - tag_loss: 0.0456 - POS_loss: 0.0478 - tag_accuracy: 0.9872 - POS_accuracy: 0.9881\n",
            "Epoch 00002: val_loss improved from 0.14176 to 0.07848, saving model to sentence_tags_pos.h5\n",
            "1199/1199 [==============================] - 1109s 925ms/step - loss: 0.0934 - tag_loss: 0.0456 - POS_loss: 0.0478 - tag_accuracy: 0.9872 - POS_accuracy: 0.9881 - val_loss: 0.0785 - val_tag_loss: 0.0411 - val_POS_loss: 0.0374 - val_tag_accuracy: 0.9884 - val_POS_accuracy: 0.9900\n",
            "Epoch 3/10\n",
            "1199/1199 [==============================] - ETA: 0s - loss: 0.0571 - tag_loss: 0.0322 - POS_loss: 0.0250 - tag_accuracy: 0.9906 - POS_accuracy: 0.9932\n",
            "Epoch 00003: val_loss improved from 0.07848 to 0.07026, saving model to sentence_tags_pos.h5\n",
            "1199/1199 [==============================] - 1098s 915ms/step - loss: 0.0571 - tag_loss: 0.0322 - POS_loss: 0.0250 - tag_accuracy: 0.9906 - POS_accuracy: 0.9932 - val_loss: 0.0703 - val_tag_loss: 0.0386 - val_POS_loss: 0.0316 - val_tag_accuracy: 0.9893 - val_POS_accuracy: 0.9911\n",
            "Epoch 4/10\n",
            "1199/1199 [==============================] - ETA: 0s - loss: 0.0460 - tag_loss: 0.0273 - POS_loss: 0.0187 - tag_accuracy: 0.9917 - POS_accuracy: 0.9945\n",
            "Epoch 00004: val_loss improved from 0.07026 to 0.06530, saving model to sentence_tags_pos.h5\n",
            "1199/1199 [==============================] - 1125s 938ms/step - loss: 0.0460 - tag_loss: 0.0273 - POS_loss: 0.0187 - tag_accuracy: 0.9917 - POS_accuracy: 0.9945 - val_loss: 0.0653 - val_tag_loss: 0.0365 - val_POS_loss: 0.0288 - val_tag_accuracy: 0.9896 - val_POS_accuracy: 0.9923\n",
            "Epoch 5/10\n",
            "1199/1199 [==============================] - ETA: 0s - loss: 0.0407 - tag_loss: 0.0244 - POS_loss: 0.0162 - tag_accuracy: 0.9924 - POS_accuracy: 0.9951\n",
            "Epoch 00005: val_loss did not improve from 0.06530\n",
            "1199/1199 [==============================] - 1145s 955ms/step - loss: 0.0407 - tag_loss: 0.0244 - POS_loss: 0.0162 - tag_accuracy: 0.9924 - POS_accuracy: 0.9951 - val_loss: 0.0656 - val_tag_loss: 0.0371 - val_POS_loss: 0.0285 - val_tag_accuracy: 0.9899 - val_POS_accuracy: 0.9924\n",
            "Epoch 6/10\n",
            "1199/1199 [==============================] - ETA: 0s - loss: 0.0360 - tag_loss: 0.0222 - POS_loss: 0.0138 - tag_accuracy: 0.9929 - POS_accuracy: 0.9957\n",
            "Epoch 00006: val_loss improved from 0.06530 to 0.06353, saving model to sentence_tags_pos.h5\n",
            "1199/1199 [==============================] - 1164s 971ms/step - loss: 0.0360 - tag_loss: 0.0222 - POS_loss: 0.0138 - tag_accuracy: 0.9929 - POS_accuracy: 0.9957 - val_loss: 0.0635 - val_tag_loss: 0.0352 - val_POS_loss: 0.0283 - val_tag_accuracy: 0.9900 - val_POS_accuracy: 0.9926\n",
            "Epoch 7/10\n",
            "1199/1199 [==============================] - ETA: 0s - loss: 0.0331 - tag_loss: 0.0206 - POS_loss: 0.0124 - tag_accuracy: 0.9934 - POS_accuracy: 0.9962\n",
            "Epoch 00007: val_loss did not improve from 0.06353\n",
            "1199/1199 [==============================] - 1150s 959ms/step - loss: 0.0331 - tag_loss: 0.0206 - POS_loss: 0.0124 - tag_accuracy: 0.9934 - POS_accuracy: 0.9962 - val_loss: 0.0638 - val_tag_loss: 0.0360 - val_POS_loss: 0.0278 - val_tag_accuracy: 0.9901 - val_POS_accuracy: 0.9927\n",
            "Epoch 8/10\n",
            "1199/1199 [==============================] - ETA: 0s - loss: 0.0304 - tag_loss: 0.0192 - POS_loss: 0.0112 - tag_accuracy: 0.9937 - POS_accuracy: 0.9965\n",
            "Epoch 00008: val_loss improved from 0.06353 to 0.06307, saving model to sentence_tags_pos.h5\n",
            "1199/1199 [==============================] - 1149s 958ms/step - loss: 0.0304 - tag_loss: 0.0192 - POS_loss: 0.0112 - tag_accuracy: 0.9937 - POS_accuracy: 0.9965 - val_loss: 0.0631 - val_tag_loss: 0.0360 - val_POS_loss: 0.0270 - val_tag_accuracy: 0.9900 - val_POS_accuracy: 0.9929\n",
            "Epoch 9/10\n",
            "1199/1199 [==============================] - ETA: 0s - loss: 0.0282 - tag_loss: 0.0179 - POS_loss: 0.0103 - tag_accuracy: 0.9941 - POS_accuracy: 0.9967\n",
            "Epoch 00009: val_loss did not improve from 0.06307\n",
            "1199/1199 [==============================] - 1148s 958ms/step - loss: 0.0282 - tag_loss: 0.0179 - POS_loss: 0.0103 - tag_accuracy: 0.9941 - POS_accuracy: 0.9967 - val_loss: 0.0651 - val_tag_loss: 0.0369 - val_POS_loss: 0.0282 - val_tag_accuracy: 0.9900 - val_POS_accuracy: 0.9927\n",
            "Epoch 10/10\n",
            "1199/1199 [==============================] - ETA: 0s - loss: 0.0261 - tag_loss: 0.0166 - POS_loss: 0.0094 - tag_accuracy: 0.9945 - POS_accuracy: 0.9970\n",
            "Epoch 00010: val_loss did not improve from 0.06307\n",
            "1199/1199 [==============================] - 1121s 935ms/step - loss: 0.0261 - tag_loss: 0.0166 - POS_loss: 0.0094 - tag_accuracy: 0.9945 - POS_accuracy: 0.9970 - val_loss: 0.0676 - val_tag_loss: 0.0379 - val_POS_loss: 0.0297 - val_tag_accuracy: 0.9901 - val_POS_accuracy: 0.9925\n",
            "CPU times: user 4h 45min 35s, sys: 40min 1s, total: 5h 25min 37s\n",
            "Wall time: 3h 9min 3s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOw4xUZmtiu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights('/content/sentence_tags_pos.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmk_i2malcCx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5ae42724-68f4-4960-bfbb-51bd1dcc88ea"
      },
      "source": [
        "i = np.random.randint(0, x_test.shape[0]) \n",
        "p = model.predict(np.array([x_test[i]]))\n",
        "p1 = np.argmax(p[0], axis=-1)\n",
        "p2 = np.argmax(p[1], axis=-1)\n",
        "y1_true = y1_test[i]\n",
        "y2_true = y2_test[i]\n",
        "print(\"{:15}{:15}\\t{:15}\\t{:15}\\t {}\\n\".format(\"Word\", \"True_tag\", \"Pred_tag\",\"True_POS\",\"Pred_POS\"))\n",
        "print(\"-\" *80)\n",
        "for w, true_tag, pred_tag, true_pos, pred_pos in zip(x_test[i], y1_true, p1[0], y2_true, p2[0]):\n",
        "    print(\"{:15}{:15}\\t{:15}\\t{:15}\\t {}\\n\".format(words[w], tags[true_tag], tags[pred_tag], POS[true_pos], POS[pred_pos]))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word           True_tag       \tPred_tag       \tTrue_POS       \t Pred_POS\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Parliamentary  O              \tO              \tJJ             \t JJ\n",
            "\n",
            "elections      O              \tO              \tNNS            \t NNS\n",
            "\n",
            "are            O              \tO              \tVBP            \t VBP\n",
            "\n",
            "set            O              \tO              \tVBN            \t VBN\n",
            "\n",
            "for            O              \tO              \tIN             \t IN\n",
            "\n",
            "October        B-tim          \tB-tim          \tNNP            \t NNP\n",
            "\n",
            "10             I-tim          \tI-tim          \tCD             \t CD\n",
            "\n",
            ".              O              \tO              \t.              \t .\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n",
            "PAD            O              \tO              \tPPAD           \t PPAD\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqhKji4il0oV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv /content/sentence_tags_pos.h5 '/content/drive/My Drive/Screencastify'"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}